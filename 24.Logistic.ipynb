{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3381d886-6835-43e4-9aa3-74fb83877d73",
   "metadata": {},
   "source": [
    "##### Fernando Amaral\n",
    "##### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec316e4b-b093-4948-883e-a779b8b29e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logist Regression Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe596d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark, pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "findspark.init()\n",
    "spark = SparkSession.builder.appName(\"logistic\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "380a2eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "|CreditScore|Geography|Gender|Age|Tenure| Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "|        619|   France|Female| 42|     2|       0|            1|        1|             1|       10134888|     1|\n",
      "|        608|    Spain|Female| 41|     1| 8380786|            1|        0|             1|       11254258|     0|\n",
      "|        502|   France|Female| 42|     8| 1596608|            3|        1|             0|       11393157|     1|\n",
      "|        699|   France|Female| 39|     1|       0|            2|        0|             0|        9382663|     0|\n",
      "|        850|    Spain|Female| 43|     2|12551082|            1|        1|             1|         790841|     0|\n",
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "churn = spark.read.csv(\"Churn.csv\", header=True, inferSchema=True, sep=\";\")\n",
    "churn.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9294eed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+----------+\n",
      "|independente                                                  |dependente|\n",
      "+--------------------------------------------------------------+----------+\n",
      "|[619.0,1.0,0.0,0.0,42.0,2.0,0.0,1.0,1.0,1.0,1.0134888E7]      |1.0       |\n",
      "|[608.0,0.0,0.0,0.0,41.0,1.0,8380786.0,1.0,0.0,1.0,1.1254258E7]|0.0       |\n",
      "|[502.0,1.0,0.0,0.0,42.0,8.0,1596608.0,3.0,1.0,0.0,1.1393157E7]|1.0       |\n",
      "|(11,[0,1,4,5,7,10],[699.0,1.0,39.0,1.0,2.0,9382663.0])        |0.0       |\n",
      "|[850.0,0.0,0.0,0.0,43.0,2.0,1.2551082E7,1.0,1.0,1.0,790841.0] |0.0       |\n",
      "+--------------------------------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we need a column with the features vectorized\n",
    "from pyspark.ml.feature import RFormula\n",
    "Rformula = RFormula(formula=\"Exited ~ .\", featuresCol=\"independente\", labelCol=\"dependente\")\n",
    "churnrf = Rformula.fit(churn).transform(churn)\n",
    "churnrf.select(\"independente\",\"dependente\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f34bddf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7907\n",
      "2093\n"
     ]
    }
   ],
   "source": [
    "# train test split \n",
    "churnTreino, churnTeste = churnrf.randomSplit([0.8,0.2])\n",
    "print(churnTreino.count())\n",
    "print(churnTeste.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88ec3c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model fit\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "logistic = LogisticRegression(featuresCol=\"independente\", labelCol=\"dependente\", maxIter=100, regParam=0.08)\n",
    "modelo = logistic.fit(churnTreino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95c046c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia:  0.8070064499810294 \n",
      "Precisão:  0.785845409667151 \n",
      "Recall:  0.8070064499810294 \n",
      "AUC  0.774166228267313\n"
     ]
    }
   ],
   "source": [
    "# model summary\n",
    "\n",
    "resumo = modelo.summary\n",
    "\n",
    "acuracia = resumo.accuracy\n",
    "precisao = resumo.weightedPrecision\n",
    "recall = resumo.weightedRecall\n",
    "auc = resumo.areaUnderROC\n",
    "\n",
    "print(\"Acurácia: \", acuracia, \"\\nPrecisão: \", precisao, \"\\nRecall: \", recall, \"\\nAUC \", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d45ca2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------------------------------------+----------------------------------------+\n",
      "|dependente|prediction|probability                             |rawPrediction                           |\n",
      "+----------+----------+----------------------------------------+----------------------------------------+\n",
      "|1.0       |0.0       |[0.8146833794235251,0.1853166205764749] |[1.4807337214829444,-1.4807337214829444]|\n",
      "|1.0       |0.0       |[0.8217900424608159,0.17820995753918412]|[1.5285225477109936,-1.5285225477109936]|\n",
      "|0.0       |0.0       |[0.8563058906626052,0.1436941093373948] |[1.7849408617488183,-1.7849408617488183]|\n",
      "|0.0       |0.0       |[0.7439320018515045,0.25606799814849546]|[1.0665066083184311,-1.0665066083184311]|\n",
      "|0.0       |0.0       |[0.9027794076014881,0.09722059239851188]|[2.228495690223417,-2.228495690223417]  |\n",
      "+----------+----------+----------------------------------------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "previsao = modelo.transform(churnTeste)\n",
    "previsao.select(\"dependente\",\"prediction\",\"probability\",\"rawPrediction\").show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ddef5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7397899106330232\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "avaliar = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"dependente\", metricName=\"areaUnderROC\")\n",
    "areaUnderRoc = avaliar.evaluate(previsao)\n",
    "print(areaUnderRoc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a153318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
